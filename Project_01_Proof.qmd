---
title: "Data Manipulation Demonstration: Manual and Functional"
author: "Brock Akerman"
date: today
format: html
---


```{r setup, echo=T, output=F}
require(tidyverse)
require(rlang)
options(readr.show_col_types = FALSE)
```

The Census Bureau’s Statistical Compendia Program collected geographical-based educational data that we aim to make useful. However, this data requires wrangling first. This demonstration will include a step-by-step explanation of the manual approach to formatting a single dataset into a useful set of tibbles for analysis. Next, I will explain a function-based approach that combines many elements of the manual method, making it easier to upload, wrangle, combine, and analyze two or more datasets. Finally, I will demonstrate how to use all the explained code to transition from raw comma-separated values to rendered ggplots.  

#### Data Processing -- The Manual Approach


```{r, echo=TRUE}
#Read-in the dataset.
EDU01a <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv")
```

We need data. The first order of business is to read a file into the R environment. A call to read_csv from the readr package and a URL pointing to a comma-separated value (CSV) file will produce our first dataset. For now, I assigned the data to an object using the original file name.

```{r, echo=TRUE}
#Select specific columns of interest from the dataset.
My_EDU01a <- EDU01a |>
  select("area_name" = Area_name, STCOU, ends_with("D"))
```

The moment I make changes to the dataset, I want to reassign the object to a new name for clarity indicating that the dataset I am now working with is not the original. With a new object name, a call to the 'select()' function in the tidyverse narrows down the columns I am interested in. The Area_name column is lowercased, STCOU remains unchanged, and I use the 'ends_with()' function to select all columns with headers ending in the letter "D".

```{r, echo=TRUE}
#Convert the data to longer formatting. 
My_EDU01a <- My_EDU01a |>
  pivot_longer(
        cols = ends_with("D"),
        names_to = "Item_ID",
        values_to = "Enrollment_Value")
```

The data is in a wide format, making it difficult to read. A call to pivot_longer() collapses all of the columns ending in "D" into a single column called "Item_ID". Values in this dataset are assigned to a new column header called "Enrollment_Value".

```{r, echo=TRUE}
#Parse Strings into numeric, survey, and measurement types.  
My_EDU01a <- My_EDU01a |>
  mutate(year = case_when(
        substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
        substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
        measure = substr(Item_ID, 1, 7))
```

Hidden within the Item_ID are two pieces of information that will assist our analysis. The last two numeric values in the ID pertain to the year of the observation, while the first seven alphanumeric characters pertain to a specific type of measure. In this step, the code below extracts both pieces of information using `substr()` and funnels them into new columns using `mutate()`.

There are two scenarios we need to account for to accurately wrangle our data. The data was collected between the 1980s and the 2010s; only the last two digits of the year are given. For our data analysis, we need to convert the newly mutated year column from a two-digit year to a four-digit year. This requires consideration for the century-spanning date range of the collected data. Using a call to `case_when()` with a subset of `substr()`, we can handle each of the scenarios and perform different actions on them based on their values. If the digit is greater than twenty-four, that would indicates that the year the data collected fell between 1980 and 1999 inclusive, as it would have been impossible to collect data from 2080 to 2099--dates which have not yet occurred. Likewise, values less than or equal to twenty-four are attributed to the years 2000 through 2024, since observations from 1900 to 1924 would not be likely based on information on this dataset provided from the Census Bureau and the gap in dates that would be present from 1924 through 1980.  Using the `paste0()` function, a "19" or "20" is added to the front of the two-digit year provided, depending on its value and then added to the 'year' column.  

The creation of the new column 'measure' was straightforward using a simple `substr()` call and removing the first seven characters from the string. The object name our mutated data will remain constant, and the dataset altered earlier with `filter()` is used here with pipes instead of the original from the readr package, thus maintaining continuity.

```{r, echo=TRUE}
#From the parameterized version of the EDU table, I have separated out the two tables by county and non-county. 
County.Data <- My_EDU01a |> filter(grepl(", [A-Z][A-Z]", area_name))
NonCounty.Data <- My_EDU01a |> filter(!grepl(", [A-Z][A-Z]", area_name))

#Add a column that identifies the classification of data we are working with. 
class(County.Data) <- c("county", class(County.Data))
class(NonCounty.Data) <- c("state", class(NonCounty.Data))
```

There is more information to extract. Our datasets can be partitioned based on whether the area_name column contains a county-state abbreviation combination or just a state. Leveraging `filter()`, `grepl()`, specific string formatting criteria, and negation logic, the following code separates the data into County and NonCounty groupings.

A class is assigned to the data. This is done because later on in the wrangling steps, both of these tibbles will be placed in a list, and we will want to set the class to "county" or "state" to accurately combine our tibbles based on their unique geographic profiles.

```{r, echo=TRUE}
# Create column in the County dataset that returns State
County.Data <- County.Data |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))
```

When plotting our data, the function will need a breakdown of county performance by state. For that, we will need a new column that contains just the state abbreviation. Here, `mutate()` and `substr()` make quick work of this task. The arguments for substr(`a`, `b`, `c`) to extract are:

`a` - the character vector\
`b` - the starting position\
`c` - the ending position\

The function `nchar()` returns the number of characters in the string. Using `nchar()` was necessary because of the varying lengths of each value in the area_name column. One pattern was uniform throughout the datasets: the last two characters of any value in this column denoted the state. In `substr()`, the first input was the column to be parsed. The second input was the number of characters in the column value minus one character—or in other words, the second-to-last character. The final input was the number of characters in the column value. This approach ensures that the mutation will always extract the last two characters of the column value.


```{r, echo=TRUE}
# Create column in the NonCounty dataset that returns division conditionally  
NonCounty.Data <- NonCounty.Data |> mutate(division = case_when(
    area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
    area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
    area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
    area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
    area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
    area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
    area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
    area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
    area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
    TRUE ~ "ERROR"
))
```

The Non-County data can be broken down into different regions, called divisions by the Census Bureau. A new column is needed to partition each group of states into their respective divisions. Creating new columns requires a call to `mutate()`. Using `case_when()`, a conditional check on the area_name column looks at a state and, if it is in a specified vector, assigns it to the appropriate division using the tilde (`~`). This involves a considerable amount of manual typing, but there are few alternatives for assigning each observation to its proper division. For cases when an area_name observation is not one of the states grouped into a division, the column value is assigned "ERROR".

The data is now organized, relevant, and ready to be analyzed. In scenarios where we might have multiple datasets to process or where we need to perform repeated actions, avoiding manual renaming of readr inputs and writing custom code is essential for saving time. Next, I will demonstrate how to address such situations. All the programming I have shown will be nested into a function. Additionally, I will introduce a new function that combines these listed tibbles based on their geographical profiles.

#### Data Processing and Combining Data -- a Functional Approach


```{r, echo=TRUE}
#The first function selects and elongates our data. 
MyFunct0102 <- function(dataset_select_pivot, Enrollment_Values = Enrollment_Values) {
  dataset_select_pivot %>%
      select("area_name" = Area_name, STCOU, ends_with("D")) %>%
      pivot_longer(
        cols = ends_with("D"),
        names_to = "Item_ID",
        values_to = "Enrollment_Value")
}
```
```{r, echo=TRUE}
#The second function creates a new column for 'year' and 'measure'.
MyFunct03 <- function(dataset_mutate) {
  dataset_mutate %>%
    mutate(year = case_when(
      substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
      substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
      measure = substr(Item_ID, 1, 7))
}
```
```{r, echo=TRUE}
#The third function creates a new column for state abbreviation inside the County Data tibble.
MyFunct05 <- function(County_Data_Mutate){
  County_Data <- County_Data_Mutate |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))
}
```

```{r, echo=TRUE}
#The fourth function creates a new column for divisional descriptors inside the NonCounty Data tibble.
MyFunct06 <- function(NonCounty_Data_Mutate){
  NonCounty_Data <- NonCounty_Data_Mutate |> mutate(division = case_when(
    area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
    area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
    area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
    area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
    area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
    area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
    area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
    area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
    area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
    TRUE ~ "ERROR"))
}
```

```{r, echo=TRUE}
#The fifth function separates our data into County vs. NonCounty, then it calls on the functions above that mutate a new column for state in the county tibble or a division column in the state tibble. Finally, it adds class to their respective tibble to make calling on it while inside a list easy.  
MyFunct04 <- function(dataset_partition) {  

  #Step 4--Separate the data into its two parts--County and NonCounty
  County_Data <- dataset_partition |> filter(grepl(", [A-Z][A-Z]", area_name))
  NonCounty_Data <- dataset_partition |> filter(!grepl(", [A-Z][A-Z]", area_name))
  
    #Function Call for CountyData
    County_Data <- MyFunct05(County_Data)
    class(County_Data) <- c("county", class(County_Data))
    
    #Function Call for NonCountyData
    NonCounty_Data <- MyFunct06(NonCounty_Data)
    class(NonCounty_Data) <- c("state", class(NonCounty_Data))
    
  return(list(County_Data = County_Data, NonCounty_Data = NonCounty_Data))
}
```

Each of the manual steps demonstrated earlier is now encapsulated into a function. Each function performs specific actions on the data. When called in the appropriate order, these functions execute the same data wrangling processes we performed earlier, but now within a single, convenient function.

```{r, echo=TRUE}
#The Wrapper Function
Split_Data_Along_Geography <- function(url, Enrollment_Value = "Enrollment_Value") {
  if (!str_ends(url, ".csv")) {
    stop("Invalid URL format. Please provide a valid URL ending in '.csv") #Check satisfying conditions for running the function. 
  }
  result <- as_tibble(read_csv(url)) %>% #Reads in data.
    MyFunct0102 %>%   #Selects/Pivots Data
    MyFunct03 %>%     #Creates new columns for measuring and date=year
    MyFunct04         #Performs the split, mutate and class call on the dataset
}
```

This wrapper function is designed to "wrap" around all other functions, ensuring they run in the required order.  User of the function will provide a URL argument and an Enrollment_Value input.  The second input is default on the column labeled "Enrollment_Value".   The first part of this function checks if the loaded file is a comma-separated values file (CSV). With increased automation, these stops and checks are necessary to prevent errors. If the supplied link does not end in ".csv", the function terminates and issues a warning. Assuming an acceptable link is provided, the function automatically reads the CSV from the URL, applies each function in the specified order, and stores the resulting data as _result_.

```{r, echo=TRUE}
#Call your data...  Test to see if the URLs produce the intended outcome. 
result_a <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv", Enrollment_Value)
result_b <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv", Enrollment_Value)
result_a; result_b;
```

```{r, echo=TRUE}
#Combine your data...  This function takes the results of two or more URLs and produces a list of combined Tibbles separated by County and NonCounty.

combine_results <- function(...) {
  results <- list(...)
  
  combined_county <- results %>%
    purrr::map(~ .x$County_Data) %>%
    purrr::reduce(dplyr::bind_rows)
  
  combined_NonCounty <- results %>%
    purrr::map(~ .x$NonCounty_Data) %>%
    purrr::reduce(dplyr::bind_rows)
  
  return(list(combined_county, combined_NonCounty))
}
combine_results(result_a, result_b)
```
Testing out the wrapper function, I called the function with the appropriate .csv file and default arguments, producing two lists, each containing a county and state tibble. Next, I used the `combine_results()` function with these lists as arguments. This function combines counties with counties and states with states across the results.

The data is ready for analysis, whether manually or through functions, and we can process many tibbles quickly if more data is needed.  It is challenging to find insights in a tibble, especially one so large.  Rather than pour over the tibble looking through thousands of rows for interesting trends, a visual aide would be a better place to start your search.  In the final demonstration, two new functions will be introduced; a unique function for each one of the county and state datasets.

#### Applications of Wrangled Data into Graphicial Insights

```{r, echo=TRUE, output=FALSE}
#Plotting function for state data
plot.state <- function(df.state, var_name = "Enrollment_Value") {
  # Filter out rows where Division is "ERROR" and compute mean enrollment of the input var_name, all by division and year.
  df_filtered <- df.state %>%
    filter(division != "ERROR") %>%
    group_by(division, year) %>%
    summarize(mean_enrollment = mean(get(var_name), na.rm = TRUE))

  # Plot the input
  ggplot(df_filtered, aes(x = year, y = mean_enrollment, color = division))+
    geom_line(aes(group = division)) +
    geom_point() +
    labs(x = "Year", y = "Mean Enrollment Values") + 
    ggtitle(paste("Mean", var_name, "across years by division")) +
    scale_y_continuous(labels = scales::comma) +
    theme(axis.text.x = element_text(angle = 90))
  }
```

The `plot.state` function accepts a dataframe classified as _state_ and a _var_name_ used to plot the mean. The function code is divided into two parts: a miniature wrangling step and the ggplot call.

Recall that we assigned _area_name_ values not listed as states as "ERROR". In the wrangling steps, the function eliminates all "ERROR" values from consideration. Then, it groups the data by division and year. Since we are interested in the performance of divisions over time, both are grouped in the `group_by()` call. Finally, a call to summarize calculates the mean _Enrollment_Value_ by default. The resulting data is assigned to the object _df_filtered_, which is prepared for use in the ggplot call.

Inside ggplot, a simple call uses the wrangled object _df_filtered_. The aesthetics include years along the x-axis and mean _Enrollment_Values_ along the y-axis. Adding color within `aes()` acts as a grouping mechanism, assigning unique colors to each division in the legend and geom layers. Towards the end of the ggplot call, there are administrative options for better presentation: appropriate labels and titles, an option to prevent scientific notation in y-axis values, and a theme adjustment to orient labels vertically for improved readability.



```{r, eval=TRUE, echo=TRUE}
plot.county <- function(data, state = "NC", var_name = "Enrollment_Value", top_or_bottom = "top", n = 5) {

  # Filter the data to only include data from the specified state
  state_data <- data %>% filter(state == !!state)

  # Calculate the overall mean of the specified statistic for each area_name
  mean_data <- state_data %>%
    group_by(area_name) %>%
    summarise(mean_value = mean(get(var_name), na.rm = TRUE))

  # Sort the mean values from largest to smallest if 'top' is specified, or smallest to largest if 'bottom' is specified
  if (top_or_bottom == "top") {
    sorted_data <- mean_data %>% arrange(desc(mean_value))
  } else {
    sorted_data <- mean_data %>% arrange(mean_value)
  }

  ## Obtain the top or bottom n area_names
  selected_areas <- sorted_data %>% slice_head(n = n) %>% pull(area_name)

  # Filter the original data to only include the selected area_names
  plot_data <- state_data %>% filter(area_name %in% selected_areas)

  ggplot(plot_data, aes(x = year, y = get(var_name), color = area_name)) +
    geom_line(aes(group = area_name)) +
    geom_point() +
    labs(x = "Year", y = "Mean Enrollment Values") + 
    ggtitle(paste(var_name, "across years by county")) +
    scale_y_continuous(labels = scales::comma) +
    theme(axis.text.x = element_text(angle = 90))
  }

#plot.county(Frames_Joined_On_Geo[[1]], state = "FL", var_name = "Enrollment_Value", top_or_bottom = "top", n = 9)
```

# Putting it all together

Run your data processing function on the two enrollment URLs given previously, specifying an appropriate name for the enrollment data column.
```{r}
#READ: EDU01a.csv file.
EDU01a <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv")

#Combine Step one, step two and step three into one task.
My_EDU01a <- EDU01a |>
  select("area_name" = Area_name, STCOU, ends_with("D")) |>
  pivot_longer(
    cols = ends_with("D"),
    names_to = "Item_ID",
    values_to = "Enrollment_Value") |> #Specification of the enrollment values data column
  mutate(year = case_when(
    substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
    substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
    measure = substr(Item_ID, 1, 7))

#Assigned data based on area_name column values.
County.Data <- My_EDU01a |> filter(grepl(", [A-Z][A-Z]", area_name))
NonCounty.Data <- My_EDU01a |> filter(!grepl(", [A-Z][A-Z]", area_name))

#Add a column that identifies the classification of data we are working with. 
class(County.Data) <- c("county", class(County.Data))
class(NonCounty.Data) <- c("state", class(NonCounty.Data))

#Create column with state abbreviation
County.Data <- County.Data |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))

#Create column in the NonCounty dataset that returns division conditionally  
NonCounty.Data <- NonCounty.Data |> mutate(division = case_when(
  area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
  area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
  area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
  area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
  area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
  area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
  area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
  area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
  area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
  TRUE ~ "ERROR"
))
County.Data
NonCounty.Data
```


```{r}
#READ: EDU01b.csv file.
EDU01b <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv")

#Combine Step one, step two and step three into one task.
My_EDU01b <- EDU01b |>
  select("area_name" = Area_name, STCOU, ends_with("D")) |>
  pivot_longer(
    cols = ends_with("D"),
    names_to = "Item_ID",
    values_to = "Enrollment_Value") |> #Specification of the enrollment values data column
  mutate(year = case_when(
    substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
    substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
    measure = substr(Item_ID, 1, 7))

#Assigned data based on area_name column values.
County.Data <- My_EDU01b |> filter(grepl(", [A-Z][A-Z]", area_name))
NonCounty.Data <- My_EDU01b |> filter(!grepl(", [A-Z][A-Z]", area_name))

#Add a column that identifies the classification of data we are working with. 
class(County.Data) <- c("county", class(County.Data))
class(NonCounty.Data) <- c("state", class(NonCounty.Data))

#Create column with state abbreviation
County.Data <- County.Data |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))

#Create column in the NonCounty dataset that returns division conditionally  
NonCounty.Data <- NonCounty.Data |> mutate(division = case_when(
  area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
  area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
  area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
  area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
  area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
  area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
  area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
  area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
  area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
  TRUE ~ "ERROR"
))
County.Data
NonCounty.Data
```

Run your data combining function to put these into one object (with two data frames)
```{r}
#Enter URL and variable input into function to assign an object in the environment.
result_a <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv", Enrollment_Value)
result_b <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv", Enrollment_Value)

#Combine the resulting lists containing two tibbles such that state combines with state and county combines with county.
joined_results <- combine_results(result_a, result_b)
joined_results
```

Use the plot function on the state data frame
```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Plot state from joined_results list element 2 (the state tibble)
plot.state(joined_results[[2]])
```

Use the plot function on the county data frame
```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once specifying the state to be “NC”, the group being the top, the number looked at being 20
plot.county(joined_results[[1]],state="NC", top_or_bottom = "top", n = 20, var_name = "Enrollment_Value")
```

```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once specifying the state to be “SC”, the group being the bottom, the number looked at being 7
plot.county(joined_results[[1]],state="SC", top_or_bottom = "bottom", n = 7, var_name = "Enrollment_Value")
```

```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once without specifying anything (defaults used)
plot.county(joined_results[[1]])
```

```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once specifying the state to be “PA”, the group being the top, the number looked at being 8
plot.county(joined_results[[1]],state="PA", top_or_bottom = "top", n = 8, var_name = "Enrollment_Value")
```


Lastly, read in another couple similar data sets and apply your functions! Run your data processing function on the four data sets at URLs given below:
 – https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv
 – https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv
 – https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv
 – https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv

```{r, eval=TRUE, echo=TRUE}
result_a <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv", Enrollment_Value)
result_b <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv", Enrollment_Value)
result_c <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv", Enrollment_Value)
result_d <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv", Enrollment_Value)
``` 
 
Run your data combining function (probably three times) to put these into one object (with two data frames)
```{r, eval=TRUE, echo=TRUE}
Four_Frames_Joined_On_Geo <- combine_results(result_a, result_b, result_c, result_d)
Four_Frames_Joined_On_Geo
```

Use the plot function on the state data frame
```{r, eval=TRUE, echo=TRUE, message=FALSE}
plot.state(Four_Frames_Joined_On_Geo[[2]])
```

Use the plot function on the county data frame
```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once specifying the state to be “CA”, the group being the top, the number looked at being 15
plot.county(Four_Frames_Joined_On_Geo[[1]],state = "CA", top_or_bottom = "top", n = 15, var_name = "Enrollment_Value")
```
```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once specifying the state to be “TX”, the group being the top, the number looked at being 4
plot.county(Four_Frames_Joined_On_Geo[[1]],state = "TX", top_or_bottom = "top", n = 4, var_name = "Enrollment_Value")
```
```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once without specifying anything (defaults used)
plot.county(Four_Frames_Joined_On_Geo[[1]])
```
```{r, eval=TRUE, echo=TRUE, message=FALSE}
#Once specifying the state to be “NY”, the group being the top, the number looked at being 1
plot.county(Four_Frames_Joined_On_Geo[[1]],state = "NY", top_or_bottom = "top", n = 1, var_name = "Enrollment_Value")
```