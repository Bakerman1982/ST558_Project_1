---
title: "Data Manipulation (EDIT TITLE)"
author: "Brock Akerman"
format: html
---

```{r setup, echo=T, output=F}
require(tidyverse)
options(readr.show_col_types = FALSE)
```

Data wrangling can present varying degrees of challenges.  If you are fortunate, issues present in the data your are working with may be corrected with a single line of Base R code in the console.  Data is messy and the task to wrangle it will often require a script of code to prepare it for analysis.

Using data from the Census Bureau's Statistical Compendia Program, we can massage the data into a format we can work with for analysis using the tidyverse.  In the following _Data Processing_ section, the effort to accomplish this task will look manual with a step-by-step demonstration of turning raw data into two tibbles that groups our data geographically using simple tidyverse functions.  In the _Combining Data Functions_ section, I will demonstrate an automative approach through nested functions.  This will allow for the replication of new datasets without having to recreate a new function each time we require the exact formatting using a similar dataset. Finally I will auto-plot the data in the _Putting it all together sections_.

# Data Processing

We cannot do anything without a dataset.  The first order of business is to introduce data to the R environment.  The readr package can read in our comma-separated value file and insert it as a tibble using the read_csv.  Since we will be working with two similarly-named URLs and datasets, I decided to name the tibble after the file name for organizational purpose.  In the next step, I would change the tibble name using best practices.

```{r}
#Read-in the dataset.
EDU01a <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv")
EDU01a
```

With the data read in, I called on it in R to show how the tibble was structured.  Observe there are 3,198 row over 42 columns of double-character mixed data.  Not all of the columns are useful.  The next tidyverse column operation will be to limit to an object the columns that we are interested in.  Inside the select operation, there is a renaming of column "Area_name" and call to pull all columns ending in "D" using the ends_with operation.     

```{r}
#1
#Select specific columns of interest from the dataset.
My_EDU01a <- EDU01a |>
  select("area_name" = Area_name, STCOU, ends_with("D"))
My_EDU01a
```

This looks better but it is still difficult to read and work with.  I want to collapse all columns ending in "D" into one column called "Item_ID".  We can better manage the tibble with the results of this collapse.  

```{r}
#2
#Convert the section to long formatting. 
My_EDU01a <- My_EDU01a |>
  pivot_longer(
        cols = ends_with("D"),
        names_to = "Item_ID",
        values_to = "Enrollment_Value")
My_EDU01a
```

Each value in the Item_ID column holds two pieces of information--a measurement type and a year.  The first 7 characters corresponds to the measurement type while the last to numerical values represent the year for the measurement.  The measure was straight-forward with a substr call to extract the first 7 characters of the Item_ID column.  We want our year in a four-number format but the dates overlapped with the new century.  This required a case_when approach of making sure all dates that were between 1980 and 1999 inclusive were fit with a "19" prefix; meanwhile, any numbers from 2000 to 2011 inclusive were fit with a "20" prefix.  I used some boolean operations to achieve this by look at the date and assigning it the appropriate prefix. Two new columns were created to show the result of both substr calls in the mutate column operation.


```{r}
#3
#Parse Strings into numeric, survey, and measurement types.  
My_EDU01a <- My_EDU01a |>
  mutate(year = case_when(
        substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
        substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
        measure = substr(Item_ID, 1, 7))
My_EDU01a
```

Our data can be broken out into two buckets; observations that are county and those that are non-county.  I used the filter operation to check each row and assign observations into one of two partitions depending on area_name formating.  I added a column for class that we will use later in the visualization section.


```{r}
# 4 From the parameterized version of the EDU table, I have separated out the two tables by county and non-county. 
County.Data <- My_EDU01a |> filter(grepl(", [A-Z][A-Z]", area_name))
NonCounty.Data <- My_EDU01a |> filter(!grepl(", [A-Z][A-Z]", area_name))

# Add a column that identifies the classification of data we are working with. 
class(County.Data) <- c("county", class(County.Data))
class(NonCounty.Data) <- c("state", class(NonCounty.Data))

County.Data
NonCounty.Data
```

The final two steps involve adding a column specific to each tibble.  For the tibble capturing county data, I have added a mutate operation which checks the area_name column and extracts the last two letters to the new column.  The tibble for state was much more complicated.  There exists many divisions that make up areas by state.  I approached this using the case_when operation.  Rows belonging to particular states where funneled into their appropriate divisions.  If the area name did not contain the name of the state the new column value would be assigned "Error".  

```{r}
# Create column in the County dataset that returns State
County.Data <- County.Data |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))

# Create column in the NonCounty dataset that returns division conditionally  
NonCounty.Data <- NonCounty.Data |> mutate(division = case_when(
    area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
    area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
    area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
    area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
    area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
    area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
    area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
    area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
    area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
    TRUE ~ "ERROR"
))

County.Data
NonCounty.Data
```



  
# Combining Data Functions

Instead of running each individual code chunk, we could create a function 

```{r}
# First Function performs steps 1 and 2 in earlier example. 
MyFunct0102 <- function(dataset_select_pivot, Enrollment_Values = Enrollment_Values) {
  dataset_select_pivot %>%
      select("area_name" = Area_name, STCOU, ends_with("D")) %>%
      pivot_longer(
        cols = ends_with("D"),
        names_to = "Item_ID",
        values_to = "Enrollment_Value")
}


# Second Function performs step 3 in earlier example. 
MyFunct03 <- function(dataset_mutate) {
  dataset_mutate %>%
    mutate(year = case_when(
      substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
      substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
      measure = substr(Item_ID, 1, 7))
}


##Step 5--Add state abbreviations to County Data
MyFunct05 <- function(County_Data_Mutate){
  County_Data <- County_Data_Mutate |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))
}


#Step 6--Add Divisional descriptors to the NonCounty Data
MyFunct06 <- function(NonCounty_Data_Mutate){
  NonCounty_Data <- NonCounty_Data_Mutate |> mutate(division = case_when(
    area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
    area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
    area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
    area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
    area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
    area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
    area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
    area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
    area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
    TRUE ~ "ERROR"))
}


# Third Function that performs steps 4 in the earlier example.  This one also calls MyFunct05 and MyFunct06
#MyFunct04 <- function(dataset_partition) {
MyFunct04 <- function(dataset_partition) {  

  #Step 4--Seperate the data into its two parts--County and NonCounty
  County_Data <- dataset_partition |> filter(grepl(", [A-Z][A-Z]", area_name))
  NonCounty_Data <- dataset_partition |> filter(!grepl(", [A-Z][A-Z]", area_name))
  
  #Function Call for CountyData
  County_Data <- MyFunct05(County_Data)
  class(County_Data) <- c("county", class(County_Data))
  #Function Call for NonCountyData
  NonCounty_Data <- MyFunct06(NonCounty_Data)
  class(NonCounty_Data) <- c("state", class(NonCounty_Data))
  
  return(list(County_Data = County_Data, NonCounty_Data = NonCounty_Data))
}


#The Wrapper Function
Split_Data_Along_Geography <- function(url, Enrollment_Value = "Enrollment_Value") {
  if (!str_ends(url, ".csv")) {
    stop("Invalid URL format. Please provide a valid URL ending in '.csv") #Check satisfying conditions for running the function. 
  }
  result <- as_tibble(read_csv(url)) %>% #Reads in data.
    MyFunct0102 %>% #Selects/Pivots Data
    MyFunct03 %>% #Creates new columns for measuring and date=year
    MyFunct04 #Performs the split, mutate and class call on the dataset
  #print(result)
}
```


```{r}
# Call it and Combine your Data.  Testing to see if the URLs produce the intended outcome so far. 
MyEDUO1a_Tibble_Wrapped <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv", Enrollment_Value)
MyEDUO1b_Tibble_Wrapped <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv", Enrollment_Value)
```


```{r}
# This function automates the step above, taking two URLs and producing a list of combined Tibbles seperated by County and NonCounty. 
combine_results <- function(MyEDUO1a_Tibble_Wrapped, MyEDUO1b_Tibble_Wrapped) {
  combined_county <- dplyr::bind_rows(MyEDUO1a_Tibble_Wrapped$County_Data, MyEDUO1b_Tibble_Wrapped$County_Data)
  combined_NonCounty <- dplyr::bind_rows(MyEDUO1a_Tibble_Wrapped$NonCounty_Data, MyEDUO1b_Tibble_Wrapped$NonCounty_Data)
  return(list(combined_county,combined_NonCounty))}

combine_results(MyEDUO1a_Tibble_Wrapped, MyEDUO1b_Tibble_Wrapped)
```
```{r}
combine_results <- function(url1, url2, Enrollment_Values = "Enrollment_Values"){
  result1 <- Split_Data_Along_Geography(url1)
  result2 <- Split_Data_Along_Geography(url2)
  combined_county <- dplyr::bind_rows(result1$County_Data, result2$County_Data)
  combined_NonCounty <- dplyr::bind_rows(result1$NonCounty_Data, result2$NonCounty_Data)
  return(list(combined_county,combined_NonCounty))}

#example
combine_results("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv","https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv",Enrollment_Values)
```




# Generic Functions

```{r}
plot.state <- function(df.state, var_name = "Enrollment_Value") {
  # Filter out rows where Division is "ERROR" and compute mean enrollment of the input var_name, all by division and year.
  df_filtered <- df.state %>%
    filter(division != "ERROR") %>%
    group_by(division, year) %>%
    summarize(mean_enrollment = mean(get(var_name), na.rm = TRUE))

  # Plot the input
  ggplot(df_filtered, aes(x = year, y = mean_enrollment, color = division))+
    geom_line(aes(group = division)) +
    geom_point() +
    labs(x = "Year", y = "Mean Enrollment Values") + 
    ggtitle(paste("Mean", var_name, "across years by division"))
  
  }

plot.county <- function(df.county, state_abbrev="FL", Top_or_Bottom = "top", Top_Bottom_Count = 5, var_name = "Enrollment_Value") {
      df_filtered <- df.county %>%
        filter(state = state) %>%
        
      #group_by(division, year) %>%
      summarize(mean_enrollment = mean(get(var_name), na.rm = TRUE))

}
MyEDUO1b_Tibble_Wrapped$County_Data


# A decision wrapper function that takes the inputs data frame and the class needing plotted, and var_name and funnels the df through the appropriate class-based plotting function

plot_by_class <- function(df, class_type, var_name = "Enrollment_Value"){
  #Stops function to abruptly stop the plot_by_class function if the df is not a list of tibbles
  if(!is.list(df)){
    stop("Input 'df' should be a list of tibbles.")
  }
  
  #Checks list of tibbles and depending on class_type called identifies and assigns the tibble to variable tibble_plot which will be used later in the wrapper function to plot.
  tibble_plot <- NULL
  for (item in df){
    if (inherits(item,class_type)) {
      tibble_plot <- item
      break
    }
  }
  
  #Stops function if the tibble not found.
  if (is.null(tibble_plot)) {
    stop(paste("No tibble with class", class_type, "was found."))
  }
  
  #Decides which function is used based on which class is called. 
  if (class_type == "state") {
    plot.state(tibble_plot, var_name)
  } else if (class_type == "county") {
    plot.county(tibble_plot, var_name)
  } else {
    stop(paste("Unsupported Class Type:", class_type))
  }
}


#plot_by_class(MyEDUO1a_Tibble_Wrapped, "state")
```

```{r}
plot.state(MyEDUO1b_Tibble_Wrapped)
```


### Putting it all together

```{r}
analyze_state_data <- function(data, state = "California", var_name, top_or_bottom = "top", n = 5) {
  # Ensure the inputs are correctly formatted
  state <- as.character(state)
  var_name <- as.character(var_name)
  top_or_bottom <- match.arg(top_or_bottom, choices = c("top", "bottom"))
  n <- as.integer(n)
  
  # 1. Filter the data to only include the specified state
  state_data <- subset(data, State == state)
  
  # 2. Find the mean of the statistic for each Area_name
  means_by_area <- aggregate(get(var_name) ~ Area_name, data = state_data, FUN = mean)
  colnames(means_by_area)[2] <- "mean_stat"  # Rename the second column to "mean_stat"
  
  # 3. Sort values according to the top or bottom specification
  if (top_or_bottom == "top") {
    sorted_means <- means_by_area[order(-means_by_area$mean_stat), ]
  } else {
    sorted_means <- means_by_area[order(means_by_area$mean_stat), ]
  }
  
  # 4. Obtain the top or bottom x number of Area_names
  top_bottom_areas <- head(sorted_means, n)
  
  # 5. Filter the state data to only include these top or bottom Area_names
  filtered_data <- subset(state_data, Area_name %in% top_bottom_areas$Area_name)
  
  return(filtered_data)
}

# Example usage:
# Suppose `data` is your data frame and 'statistic_column' is the column name of the statistic you are interested in.
# filtered_data <- analyze_state_data(data, state = "New York", var_name = "statistic_column", top_or_bottom = "bottom", n = 10)

```