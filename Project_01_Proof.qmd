---
title: "Data Manipulation (EDIT TITLE)"
author: "Brock Akerman"
format: html
---

```{r setup, echo=T, output=F}
require(tidyverse)
options(readr.show_col_types = FALSE)
```

Data wrangling can present varying degrees of challenges.  If you are fortunate, issues present in the data your are working with may be corrected with a single line of Base R code in the console.  Data is messy and the task to wrangle it will often require a script of code to prepare it for analysis.

Using data from the Census Bureau's Statistical Compendia Program, we can massage the data into a format we can work with for analysis using the tidyverse.  In the following _Data Processing_ section, the effort to accomplish this task will look manual with a step-by-step demonstration of turning raw data into two tibbles that groups our data geographically using simple tidyverse functions.  In the _Combining Data Functions_ section, I will demonstrate an automative approach through nested functions.  This will allow for the replication of new datasets without having to recreate a new function each time we require the exact formatting using a similar dataset. Finally I will auto-plot the data in the _Putting it all together sections_.

### Data Processing

We cannot do anything without a dataset.  The first order of business is to introduce data to the R environment.  The readr package can read in our comma-separated value file and insert it as a tibble using the read_csv.  Since we will be working with two similarly-named URLs and datasets, I decided to name the tibble after the file name for organizational purpose.  In the next step, I would change the tibble name using best practices.

```{r}
#Read-in the dataset.
EDU01a <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv")
EDU01a
```

With the data read in, I called on it in R to show how the tibble was structured.  Observe there are 3,198 row over 42 columns of double-character mixed data.  Not all of the columns are useful.  The next tidyverse column operation will be to limit to an object the columns that we are interested in.  Inside the select operation, there is a renaming of column "Area_name" and call to pull all columns ending in "D" using the ends_with operation.     

```{r}
#1
#Select specific columns of interest from the dataset.
My_EDU01a <- EDU01a |>
  select("area_name" = Area_name, STCOU, ends_with("D"))
My_EDU01a
```

This looks better but it is still difficult to read and work with.  I want to collapse all columns ending in "D" into one column called "Item_ID".  We can better manage the tibble with the results of this collapse.  

```{r}
#2
#Convert the section to long formatting. 
My_EDU01a <- My_EDU01a |>
  pivot_longer(
        cols = ends_with("D"),
        names_to = "Item_ID",
        values_to = "Enrollment_Value")
My_EDU01a
```

Each value in the Item_ID column holds two pieces of information--a measurement type and a year.  The first 7 characters corresponds to the measurement type while the last to numerical values represent the year for the measurement.  The measure was straight-forward with a substr call to extract the first 7 characters of the Item_ID column.  We want our year in a four-number format but the dates overlapped with the new century.  This required a case_when approach of making sure all dates that were between 1980 and 1999 inclusive were fit with a "19" prefix; meanwhile, any numbers from 2000 to 2011 inclusive were fit with a "20" prefix.  I used some boolean operations to achieve this by look at the date and assigning it the appropriate prefix. Two new columns were created to show the result of both substr calls in the mutate column operation.


```{r}
#3
#Parse Strings into numeric, survey, and measurement types.  
My_EDU01a <- My_EDU01a |>
  mutate(year = case_when(
        substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
        substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
        measure = substr(Item_ID, 1, 7))
My_EDU01a
```

Our data can be broken out into two buckets; observations that are county and those that are non-county.  I used the filter operation to check each row and assign observations into one of two partitions depending on area_name formating.  I added a column for class that we will use later in the visualization section.


```{r}
# 4 From the parameterized version of the EDU table, I have separated out the two tables by county and non-county. 
County.Data <- My_EDU01a |> filter(grepl(", [A-Z][A-Z]", area_name))
NonCounty.Data <- My_EDU01a |> filter(!grepl(", [A-Z][A-Z]", area_name))

# Add a column that identifies the classification of data we are working with. 
class(County.Data) <- c("county", class(County.Data))
class(NonCounty.Data) <- c("state", class(NonCounty.Data))

County.Data
NonCounty.Data
```

The final two steps involve adding a column specific to each tibble.  For the tibble capturing county data, I have added a mutate operation which checks the area_name column and extracts the last two letters to the new column.  The tibble for state was much more complicated.  There exists many divisions that make up areas by state.  I approached this using the case_when operation.  Rows belonging to particular states where funneled into their appropriate divisions.  If the area name did not contain the name of the state the new column value would be assigned "Error".  

```{r}
# Create column in the County dataset that returns State
County.Data <- County.Data |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))

# Create column in the NonCounty dataset that returns division conditionally  
NonCounty.Data <- NonCounty.Data |> mutate(division = case_when(
    area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
    area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
    area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
    area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
    area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
    area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
    area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
    area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
    area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
    TRUE ~ "ERROR"
))

County.Data
NonCounty.Data
```




  
### Combining Data Functions

Instead of running each individual code chunk, we could create a function 

```{r}
# First Function performs steps 1 and 2 in earlier example. 
MyFunct0102 <- function(dataset_select_pivot, Enrollment_Values = Enrollment_Values) {
  dataset_select_pivot %>%
      select("area_name" = Area_name, STCOU, ends_with("D")) %>%
      pivot_longer(
        cols = ends_with("D"),
        names_to = "Item_ID",
        values_to = "Enrollment_Value")
}


# Second Function performs step 3 in earlier example. 
MyFunct03 <- function(dataset_mutate) {
  dataset_mutate %>%
    mutate(year = case_when(
      substr(Item_ID, 8, 9) > 24 ~ paste0("19", substr(Item_ID, 8,9)),  
      substr(Item_ID, 8, 9) <= 24 ~ paste0("20", substr(Item_ID, 8,9))),
      measure = substr(Item_ID, 1, 7))
}


##Step 5--Add state abbreviations to County Data
MyFunct05 <- function(County_Data_Mutate){
  County_Data <- County_Data_Mutate |> mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))
}


#Step 6--Add Divisional descriptors to the NonCounty Data
MyFunct06 <- function(NonCounty_Data_Mutate){
  NonCounty_Data <- NonCounty_Data_Mutate |> mutate(division = case_when(
    area_name %in% c("CONNECTICUT","MAINE","MASSACHUSETTS","NEW HAMPSHIRE","RHODE ISLAND","VERMONT") ~ "New England",
    area_name %in% c("NEW JERSEY","NEW YORK","PENNSYLVANIA") ~ "Midwest",
    area_name %in% c("ILLINOIS","INDIANA","MICHIGAN","OHIO","WISCONSIN") ~ "East North Central",
    area_name %in% c("IOWA","KANSAS","MINNESOTA","MISSOURI","NEBRASKA","NORTH DAKOTA","SOUTH DAKOTA") ~ "West North Central",
    area_name %in% c("DELAWARE","FLORIDA","GEORGIA","MARYLAND","NORTH CAROLINA","SOUTH CAROLINA","VIRGINIA","WASHINGTON, D.C.","WEST VIRGINIA") ~ "South Atlantic",
    area_name %in% c("ALABAMA","KENTUCKY","MISSISSIPPI","TENNESSEE") ~ "East South Central",
    area_name %in% c("ARKANSAS","LOUISIANA","OKLAHOMA","TEXAS") ~ "West South Central",
    area_name %in% c("ARIZONA","COLORADO","IDAHO","MONTANA","NEVADA","NEW MEXICO","UTAH","WYOMING") ~ "Mountain",
    area_name %in% c("ALASKA","CALIFORNIA","HAWAII","OREGON","WASHINGTON") ~ "Pacific",
    TRUE ~ "ERROR"))
}


# Third Function that performs steps 4 in the earlier example.  This one also calls MyFunct05 and MyFunct06
#MyFunct04 <- function(dataset_partition) {
MyFunct04 <- function(dataset_partition) {  

  #Step 4--Seperate the data into its two parts--County and NonCounty
  County_Data <- dataset_partition |> filter(grepl(", [A-Z][A-Z]", area_name))
  NonCounty_Data <- dataset_partition |> filter(!grepl(", [A-Z][A-Z]", area_name))
  
  #Function Call for CountyData
  County_Data <- MyFunct05(County_Data)
  class(County_Data) <- c("county", class(County_Data))
  #Function Call for NonCountyData
  NonCounty_Data <- MyFunct06(NonCounty_Data)
  class(NonCounty_Data) <- c("state", class(NonCounty_Data))
  
  return(list(County_Data = County_Data, NonCounty_Data = NonCounty_Data))
}


#The Wrapper Function
Split_Data_Along_Geography <- function(url, Enrollment_Value = "Enrollment_Value") {
  if (!str_ends(url, ".csv")) {
    stop("Invalid URL format. Please provide a valid URL ending in '.csv") #Check satisfying conditions for running the function. 
  }
  result <- as_tibble(read_csv(url)) %>% #Reads in data.
    MyFunct0102 %>% #Selects/Pivots Data
    MyFunct03 %>% #Creates new columns for measuring and date=year
    MyFunct04 #Performs the split, mutate and class call on the dataset
  print(result)
}
```


```{r}
# Call it and Combine your Data
MyEDUO1a_Tibble_Wrapped <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv", Enrollment_Value)
MyEDUO1b_Tibble_Wrapped <- Split_Data_Along_Geography("https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv", Enrollment_Value)
```


```{r}

combine_results <- function(MyEDUO1a_Tibble_Wrapped, MyEDUO1b_Tibble_Wrapped) {
  combined_county <- dplyr::bind_rows(MyEDUO1a_Tibble_Wrapped$County_Data, MyEDUO1b_Tibble_Wrapped$County_Data)
  combined_NonCounty <- dplyr::bind_rows(MyEDUO1a_Tibble_Wrapped$NonCounty_Data, MyEDUO1b_Tibble_Wrapped$NonCounty_Data)
  return(list(combined_county,combined_NonCounty))}

combine_results(MyEDUO1a_Tibble_Wrapped, MyEDUO1b_Tibble_Wrapped)

```


### Generic Functions
```{r}
#plot the mean value of the statistic Enrollment_Value across years for each division.  
#X axis = numeric year values, 
#y axis = mean stat of Enrollment_Value by division and year
#Remove obsevations that have ERROR in division. 


plot.state <- function(df, var_name = "Enrollment_Value"){
  #Check to make sure the required columns exist in the data frame
  if (!all("division", "year", var_name) %in% names(df)) {
    stop("Data must contain one each of the following column headers: Division, Year, and specified 'var_name' input.")
  }
  
  #Remove the "ERROR" values from consideration
  summart_df
    summary_df <- df %>%
    filter(Division != "ERROR") %>%
    group_by(Division, Year) %>%
    summarize(mean_value = mean(get(var_name), na.rm = TRUE), .groups = 'drop')
  
  # Create the plot
  ggplot(summary_df, aes(x = Year, y = mean_value, color = Division)) +
    geom_line() +
    geom_point() +
    labs(
      title = paste("Mean", var_name, "by Division and Year"),
      x = "Year",
      y = paste("Mean", var_name)
    ) +
    theme_minimal()
}


#plot.state(Reconstituted_MyEDU01a)
```
### Putting it all together

